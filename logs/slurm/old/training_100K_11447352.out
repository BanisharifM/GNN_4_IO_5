2025-08-12 20:54:43,322 - INFO - ================================================================================
2025-08-12 20:54:43,322 - INFO - GAT TRAINING FOR I/O PERFORMANCE PREDICTION
2025-08-12 20:54:43,322 - INFO - ================================================================================
2025-08-12 20:54:43,325 - INFO - Random seed: 7
2025-08-12 20:54:43,325 - INFO - Using device: cuda
2025-08-12 20:54:43,333 - INFO - Configuration saved to experiments/gat_baseline/config.yaml
2025-08-12 20:54:43,333 - INFO - 
========================================
2025-08-12 20:54:43,333 - INFO - LOADING DATASET
2025-08-12 20:54:43,333 - INFO - ========================================
2025-08-12 20:54:44,141 - INFO - Dataset loaded: 100,000 nodes, 5,000,000 edges
2025-08-12 20:54:44,141 - INFO - Features: torch.Size([100000, 45]), Targets: torch.Size([100000, 1])
2025-08-12 20:54:44,265 - INFO - Data splits - Train: 60,000, Val: 20,000, Test: 20,000
2025-08-12 20:54:44,267 - INFO - 
========================================
2025-08-12 20:54:44,267 - INFO - SETTING UP DATA LOADER
2025-08-12 20:54:44,267 - INFO - ========================================
2025-08-12 20:54:44,267 - INFO - Using mini-batch data loading
2025-08-12 20:54:44,694 - INFO - Train loader: 60,000 nodes, 30 batches
2025-08-12 20:54:45,089 - INFO - Val loader: 20,000 nodes, 5 batches
2025-08-12 20:54:45,468 - INFO - Test loader: 20,000 nodes, 5 batches
2025-08-12 20:54:45,722 - INFO - Memory stats: {'gpu_allocated': 0.0, 'gpu_reserved': 0.0, 'gpu_total': 143.771, 'gpu_free': 142.547, 'gpu_used': 0.526, 'ram_available': 2070.941282304, 'ram_used': 66.979278848, 'ram_total': 2164.173791232}
2025-08-12 20:54:45,722 - INFO - Memory stats: {'gpu_allocated': 0.0, 'gpu_reserved': 0.0, 'gpu_total': 143.771, 'gpu_free': 142.547, 'gpu_used': 0.526, 'ram_available': 2070.941282304, 'ram_used': 66.979278848, 'ram_total': 2164.173791232}
2025-08-12 20:54:45,722 - INFO - 
========================================
2025-08-12 20:54:45,722 - INFO - CREATING MODEL
2025-08-12 20:54:45,722 - INFO - ========================================
2025-08-12 20:54:46,568 - INFO - Model: IOPerformanceGAT
2025-08-12 20:54:46,568 - INFO - Total parameters: 94,910,465
2025-08-12 20:54:46,568 - INFO - Trainable parameters: 94,910,465
2025-08-12 20:54:46,568 - INFO - 
========================================
2025-08-12 20:54:46,568 - INFO - SETTING UP TRAINER
2025-08-12 20:54:46,568 - INFO - ========================================
2025-08-12 20:54:46,661 - INFO - 
========================================
2025-08-12 20:54:46,661 - INFO - STARTING TRAINING
2025-08-12 20:54:46,661 - INFO - ========================================
2025-08-12 20:54:46,662 - INFO - Training for 300 epochs
2025-08-12 20:54:46,662 - INFO - Early stopping patience: 50
2025-08-12 20:54:46,662 - INFO - AIIO Best Baseline: 0.186
2025-08-12 20:54:46,662 - INFO - AIIO LightGBM: 0.2632
2025-08-12 20:54:46,662 - INFO - Starting training for 300 epochs on cuda
2025-08-12 20:54:46,662 - INFO - AIIO baselines - Best: 0.186, LightGBM: 0.2632
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:01<?, ?it/s]
2025-08-12 20:54:47,853 - ERROR - Training failed: CUDA out of memory. Tried to allocate 14.94 GiB (GPU 0; 139.72 GiB total capacity; 124.16 GiB already allocated; 2.80 GiB free; 136.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/work/hdd/bdau/mbanisharifdehkordi/GNN_4_IO_5/scripts/train_gat.py", line 447, in <module>
    final_rmse = main(args)
  File "/work/hdd/bdau/mbanisharifdehkordi/GNN_4_IO_5/scripts/train_gat.py", line 257, in main
    history = trainer.train(
  File "/work/hdd/bdau/mbanisharifdehkordi/GNN_4_IO_5/src/training/trainer.py", line 349, in train
    train_metrics = self.train_epoch_mini_batch(train_data['train'])
  File "/work/hdd/bdau/mbanisharifdehkordi/GNN_4_IO_5/src/training/trainer.py", line 216, in train_epoch_mini_batch
    out = self.model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)
  File "/u/mbanisharifdehkordi/.conda/envs/gnn4_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/hdd/bdau/mbanisharifdehkordi/GNN_4_IO_5/src/models/gat.py", line 267, in forward
    x, att = self.gat_layers[i](
  File "/u/mbanisharifdehkordi/.conda/envs/gnn4_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/hdd/bdau/mbanisharifdehkordi/GNN_4_IO_5/src/models/gat.py", line 67, in forward
    out, attention = self.gat_conv(
  File "/u/mbanisharifdehkordi/.conda/envs/gnn4_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/u/mbanisharifdehkordi/.conda/envs/gnn4_env/lib/python3.9/site-packages/torch_geometric/nn/conv/gat_conv.py", line 366, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/tmp/torch_geometric.nn.conv.gat_conv_GATConv_propagate_1rt5gojp.py", line 176, in propagate
    out = self.message(
  File "/u/mbanisharifdehkordi/.conda/envs/gnn4_env/lib/python3.9/site-packages/torch_geometric/nn/conv/gat_conv.py", line 414, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.94 GiB (GPU 0; 139.72 GiB total capacity; 124.16 GiB already allocated; 2.80 GiB free; 136.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Training complete! Results saved to ./experiments/gat_exp_20250812_205436
