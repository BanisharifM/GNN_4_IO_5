# GAT Configuration for I/O Performance Prediction

# Data settings
data:
  root: "./data/processed"
  train_ratio: 0.6
  val_ratio: 0.2
  test_ratio: 0.2
  stratify: true  # Stratify by performance

# Model architecture
model:
  type: "deep"  # Options: standard, lightweight, deep
  hidden_channels: 512
  num_layers: 4
  heads: [16, 8, 4, 1]  # Attention heads per layer
  dropout: 0.1
  edge_dim: 1  # Similarity score dimension
  residual: true
  layer_norm: true
  feature_augmentation: true
  pool_type: "mean"  # Options: mean, max, add
  dtype: "float32"

# Training settings
training:
  epochs: 300
  learning_rate: 0.0005
  weight_decay: 0.0001
  optimizer: "adamw"  # Options: adam, adamw, sgd
  scheduler: "cosine"  # Options: plateau, cosine, step
  gradient_clip: 1.0
  early_stopping_patience: 50
  dtype: "float32"
  
  # Batch settings
  batch_size: 2048
  num_neighbors: [25, 10]  # Neighbors per layer for mini-batch
  accumulation_steps: 1
  
  # Mixed precision (set false for float64)
  mixed_precision: false

# Experiment settings
experiment:
  seed: 7
  use_wandb: false
  project_name: "io_performance_gnn"
  run_name: "gat_baseline_run"

# AIIO baselines for comparison (RMSE values)
aiio_baselines:
  XGBoost: 0.5634
  LightGBM: 0.2632
  CatBoost: 0.2686
  MLP: 0.5416
  TabNet: 0.3078
  Closest_Method: 0.1860
  Average_Method: 0.2405

# Interpretability settings
interpretability:
  attention_analysis: true
  gnn_explainer: true
  gradient_methods: true
  num_samples_to_analyze: 10
  save_visualizations: true