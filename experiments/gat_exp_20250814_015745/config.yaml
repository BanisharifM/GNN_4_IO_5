aiio_baselines:
  Average_Method: 0.2405
  CatBoost: 0.2686
  Closest_Method: 0.186
  LightGBM: 0.2632
  MLP: 0.5416
  TabNet: 0.3078
  XGBoost: 0.5634
data:
  features_csv_path: /work/hdd/bdau/mbanisharifdehkordi/GNN_4_IO_5/data/100K/aiio_sample_100000_normalized.csv
  root: ./data/processed
  similarity_npz_path: /work/hdd/bdau/mbanisharifdehkordi/GNN_4_IO_5/data/100K/similarity_output_0.75/similarity_graph_20250812_002240.npz
  similarity_pt_path: /work/hdd/bdau/mbanisharifdehkordi/GNN_4_IO_5/data/100K/similarity_output_0.75/similarity_graph_20250812_002240.pt
  stratify: true
  test_ratio: 0.2
  train_ratio: 0.6
  val_ratio: 0.2
experiment:
  project_name: io_performance_gnn
  run_name: gat_100k_20250814_015745
  save_dir: ./experiments/gat_exp_20250814_015745
  seed: 7
  use_wandb: false
interpretability:
  attention_analysis: true
  gnn_explainer: true
  gradient_methods: true
  num_samples_to_analyze: 10
  save_visualizations: true
model:
  dropout: 0.2
  dtype: float32
  edge_dim: 1
  feature_augmentation: true
  heads:
  - 8
  - 8
  - 1
  hidden_channels: 256
  layer_norm: true
  num_layers: 3
  pool_type: mean
  residual: true
  type: standard
training:
  accumulation_steps: 1
  batch_size: 2048
  dtype: float32
  early_stopping_patience: 30
  epochs: 200
  gradient_clip: 1.0
  learning_rate: 0.001
  mixed_precision: false
  num_neighbors:
  - 25
  - 10
  optimizer: adamw
  scheduler: plateau
  weight_decay: 1.0e-05
